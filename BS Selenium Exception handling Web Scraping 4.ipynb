{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d97f5959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException,ElementNotInteractableException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1fbb1a",
   "metadata": {},
   "source": [
    "Q1.Scrape the details of most viewed videos on YouTube from Wikipedia: Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/ You need to find following details: A) Rank B) Name C) Artist D) Upload date E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "323cb13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-cf916a80d76d>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n",
      "<ipython-input-2-cf916a80d76d>:13: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  names=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\")\n",
      "<ipython-input-2-cf916a80d76d>:25: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  ranks=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\")\n",
      "<ipython-input-2-cf916a80d76d>:37: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  artists=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
      "<ipython-input-2-cf916a80d76d>:49: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  views_list=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
      "<ipython-input-2-cf916a80d76d>:61: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  upload_date_list=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Uploader/artist</th>\n",
       "      <th>Date of upload</th>\n",
       "      <th>Views(in billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[3]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>10.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[6]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[12]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[13]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[15]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Bath Song\"[20]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[21]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[22]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[23]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[24]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[25]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Dame Tu Cosita\"[30]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Wheels on the Bus\"[31]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[32]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[33]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[34]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Sorry\"[35]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Thinking Out Loud\"[36]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Girls Like You\"[38]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Faded\"[39]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[40]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Let Her Go\"[41]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Bailando\"[42]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Lean On\"[43]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[44]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Shake It Off\"[45]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[47]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Mi Gente\"[48]</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[3]   \n",
       "1    2.                                   \"Despacito\"[6]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[12]   \n",
       "3    4.                               \"Shape of You\"[13]   \n",
       "4    5.                              \"See You Again\"[15]   \n",
       "5    6.                                  \"Bath Song\"[20]   \n",
       "6    7.  \"Learning Colors – Colorful Eggs on a Farm\"[21]   \n",
       "7    8.                \"Phonics Song with Two Words\"[22]   \n",
       "8    9.                                \"Uptown Funk\"[23]   \n",
       "9   10.   \"Masha and the Bear – Recipe for Disaster\"[24]   \n",
       "10  11.                              \"Gangnam Style\"[25]   \n",
       "11  12.                             \"Dame Tu Cosita\"[30]   \n",
       "12  13.                          \"Wheels on the Bus\"[31]   \n",
       "13  14.                                      \"Sugar\"[32]   \n",
       "14  15.                                       \"Roar\"[33]   \n",
       "15  16.                             \"Counting Stars\"[34]   \n",
       "16  17.                                      \"Sorry\"[35]   \n",
       "17  18.                          \"Thinking Out Loud\"[36]   \n",
       "18  19.                                     \"Axel F\"[37]   \n",
       "19  20.                             \"Girls Like You\"[38]   \n",
       "20  21.                                      \"Faded\"[39]   \n",
       "21  22.                                 \"Dark Horse\"[40]   \n",
       "22  23.                                 \"Let Her Go\"[41]   \n",
       "23  24.                                   \"Bailando\"[42]   \n",
       "24  25.                                    \"Lean On\"[43]   \n",
       "25  26.                        \"Baa Baa Black Sheep\"[44]   \n",
       "26  27.                               \"Shake It Off\"[45]   \n",
       "27  28.                                    \"Perfect\"[46]   \n",
       "28  29.           \"Waka Waka (This Time for Africa)\"[47]   \n",
       "29  30.                                   \"Mi Gente\"[48]   \n",
       "\n",
       "                                Uploader/artist     Date of upload  \\\n",
       "0   Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                    Luis Fonsi   January 12, 2017   \n",
       "2                                   LooLoo Kids    October 8, 2016   \n",
       "3                                    Ed Sheeran   January 30, 2017   \n",
       "4                                   Wiz Khalifa      April 6, 2015   \n",
       "5                    Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "6                                   Miroshka TV  February 27, 2018   \n",
       "7                                     ChuChu TV      March 6, 2014   \n",
       "8                                   Mark Ronson  November 19, 2014   \n",
       "9                                    Get Movies   January 31, 2012   \n",
       "10                                          Psy      July 15, 2012   \n",
       "11                                    El Chombo      April 5, 2018   \n",
       "12                   Cocomelon – Nursery Rhymes       May 24, 2018   \n",
       "13                                     Maroon 5   January 14, 2015   \n",
       "14                                   Katy Perry  September 5, 2013   \n",
       "15                                  OneRepublic       May 31, 2013   \n",
       "16                                Justin Bieber   October 22, 2015   \n",
       "17                                   Ed Sheeran    October 7, 2014   \n",
       "18                                   Crazy Frog      June 16, 2009   \n",
       "19                                     Maroon 5       May 31, 2018   \n",
       "20                                  Alan Walker   December 3, 2015   \n",
       "21                                   Katy Perry  February 20, 2014   \n",
       "22                                    Passenger      July 25, 2012   \n",
       "23                             Enrique Iglesias     April 11, 2014   \n",
       "24                                  Major Lazer     March 22, 2015   \n",
       "25                   Cocomelon – Nursery Rhymes      June 25, 2018   \n",
       "26                                 Taylor Swift    August 18, 2014   \n",
       "27                                   Ed Sheeran   November 9, 2017   \n",
       "28                                      Shakira       June 4, 2010   \n",
       "29                                     J Balvin      June 29, 2017   \n",
       "\n",
       "   Views(in billion)  \n",
       "0              10.33  \n",
       "1               7.78  \n",
       "2               6.23  \n",
       "3               5.65  \n",
       "4               5.44  \n",
       "5               5.10  \n",
       "6               4.56  \n",
       "7               4.51  \n",
       "8               4.49  \n",
       "9               4.49  \n",
       "10              4.36  \n",
       "11              3.89  \n",
       "12              3.79  \n",
       "13              3.66  \n",
       "14              3.54  \n",
       "15              3.53  \n",
       "16              3.52  \n",
       "17              3.42  \n",
       "18              3.27  \n",
       "19              3.25  \n",
       "20              3.25  \n",
       "21              3.24  \n",
       "22              3.19  \n",
       "23              3.18  \n",
       "24              3.18  \n",
       "25              3.17  \n",
       "26              3.15  \n",
       "27              3.11  \n",
       "28              3.08  \n",
       "29              3.05  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(2)\n",
    "\n",
    "# Opening the wikipedia\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "#scraping names of the video\n",
    "name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\")\n",
    "    for i in names:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    name.append('No details available')\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    name.append('No details available')\n",
    "    \n",
    "time.sleep(2)    \n",
    "#scraping rank of the video\n",
    "rank=[]\n",
    "try:\n",
    "    ranks=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\")\n",
    "    for i in ranks:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    rank.append('No details available')\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    rank.append('No details available')\n",
    "\n",
    "time.sleep(2)\n",
    "#scraping artist/uploader of the video\n",
    "artist=[]\n",
    "try:\n",
    "    artists=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
    "    for i in artists:\n",
    "        artist.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    artist.append('No details available')\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    artist.append('No details available')\n",
    "    \n",
    "time.sleep(2)    \n",
    "#scraping views of the video\n",
    "views=[]\n",
    "try:\n",
    "    views_list=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "    for i in views_list:\n",
    "        views.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    views.append('No details available')\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    views.append('No details available')\n",
    "    \n",
    "time.sleep(2)    \n",
    "#scraping views of the video\n",
    "upload_date=[]\n",
    "try:\n",
    "    upload_date_list=driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "    for i in upload_date_list:\n",
    "        upload_date.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    upload_date.append('No details available')\n",
    "except StaleElementReferenceException:#handling Stale element exception\n",
    "    upload_date.append('No details available')\n",
    "    \n",
    "time.sleep(2)    \n",
    "#preparing dataframe\n",
    "df=pd.DataFrame({\"Rank\":rank,\n",
    "                 \"Name\":name,\n",
    "                \"Uploader/artist\":artist,\n",
    "                \"Date of upload\":upload_date,\n",
    "                \"Views(in billion)\":views})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867e4bec",
   "metadata": {},
   "source": [
    "Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/. You need to find following details: A) Match title (I.e. 1 st ODI) B) Series C) Place D) Date E) Time Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a455ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-f54c79595346>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('chromedriver.exe')\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4661f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://www.bcci.tv/'\n",
    "driver.get(url1)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "905c76ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-975f1c4b548b>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  fixtures=driver.find_element_by_xpath(\"//li[@class='nav-item ml-0']\")\n"
     ]
    }
   ],
   "source": [
    "fixtures=driver.find_element_by_xpath(\"//li[@class='nav-item ml-0']\") \n",
    "try:\n",
    "    fixtures.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(fixtures.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b3ee740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-a2784623e34e>:7: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  time_title=driver.find_elements_by_xpath(\"//h5[@class='text-right ng-binding']\")\n"
     ]
    }
   ],
   "source": [
    "match=[] \n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "Time=[]\n",
    "\n",
    "time_title=driver.find_elements_by_xpath(\"//h5[@class='text-right ng-binding']\")\n",
    "for i in time_title:\n",
    "    if i.text is None :\n",
    "        Time.append(\"--\") \n",
    "    else:\n",
    "        Time.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc16018f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-5ff70b9e5b5f>:2: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  match_page=driver.find_elements_by_xpath(\"//a[@class='match-center-btn ng-scope']\")\n"
     ]
    }
   ],
   "source": [
    "urls=[]\n",
    "match_page=driver.find_elements_by_xpath(\"//a[@class='match-center-btn ng-scope']\")  \n",
    "for i in match_page:\n",
    "    urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "639b2d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-cfa2c7649638>:2: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  match_page=driver.find_elements_by_xpath(\"//a[@class='match-center-btn ng-scope']\")\n"
     ]
    }
   ],
   "source": [
    "urls=[]\n",
    "match_page=driver.find_elements_by_xpath(\"//a[@class='match-center-btn ng-scope']\")  \n",
    "for i in match_page:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "      \n",
    "time.sleep(1)   \n",
    "\n",
    "for i in urls:   \n",
    "    driver.get(i)\n",
    "    \n",
    "    time.sleep(2)\n",
    "    try:                    \n",
    "        match_title=driver.find_element_by_xpath(\"//div[@class='widget matchDetails hideMobOnly showForSpecialCase']/div/ul/li[2]/span[2]\")\n",
    "        match.append(match_title.text)\n",
    "    except NoSuchElementException:\n",
    "        match.append('No details available')\n",
    "    \n",
    "    time.sleep(2)  \n",
    "    try:\n",
    "        series_title=driver.find_element_by_xpath(\"//div[@class='widget matchDetails hideMobOnly showForSpecialCase']/div/ul/li[1]/span[2]\")\n",
    "        series.append(series_title.text)\n",
    "    except NoSuchElementException:\n",
    "        series.append(\"No details Available\")\n",
    "    \n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        date_title=driver.find_element_by_xpath(\"//div[@class='matchDate alignC ng-binding ng-scope']\")\n",
    "        date.append(date_title.text)\n",
    "    except NoSuchElementException:\n",
    "        date.append(\"No details Available\")      \n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        place_title=driver.find_element_by_xpath(\"//div[@class='widget matchDetails hideMobOnly showForSpecialCase']/div/ul/li[3]/span[2]\")\n",
    "        place.append(place_title.text)\n",
    "    except NoSuchElementException:\n",
    "        place.append(\"No details Available\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f0b292b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Match, Series, Place, Date, Time]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        \n",
    "df=pd.DataFrame({\"Match\":match,\n",
    "                \"Series\":series,\n",
    "                \"Place\":place,\n",
    "                \"Date\":date,\n",
    "                \"Time\":Time})\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fc64ea",
   "metadata": {},
   "source": [
    "Q3 - Scrape the details of selenium exception from guru99.com. Url = https://www.guru99.com/ You need to find following details: A) Name B) Description Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e7d05e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-b0111774bc0f>:4: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  selenium = driver.find_element_by_xpath('//ul[@class=\"menu1\"]/li[3]')\n"
     ]
    }
   ],
   "source": [
    "url2 = 'https://www.guru99.com/'\n",
    "driver.get(url2)\n",
    "time.sleep(5)\n",
    "selenium = driver.find_element_by_xpath('//ul[@class=\"menu1\"]/li[3]') \n",
    "selenium.click()\n",
    "\n",
    "#After running this cell, please wait till the webpage get's loaded completly it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f146f4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-63-7a47d357945b>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  exception = driver.find_element_by_xpath('//table[@class=\"table\"][5]/tbody/tr[34 ]/td[1]')\n"
     ]
    }
   ],
   "source": [
    "exception = driver.find_element_by_xpath('//table[@class=\"table\"][5]/tbody/tr[34 ]/td[1]') \n",
    "exception.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9048f167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-64-764aefb40185>:4: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  nam = driver.find_elements_by_xpath('//table[@class=\"table table-striped\"]/tbody/tr/td[1]')\n",
      "<ipython-input-64-764aefb40185>:5: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  des = driver.find_elements_by_xpath('//table[@class=\"table table-striped\"]/tbody/tr/td[2]')\n"
     ]
    }
   ],
   "source": [
    "name = []           \n",
    "description = []\n",
    "\n",
    "nam = driver.find_elements_by_xpath('//table[@class=\"table table-striped\"]/tbody/tr/td[1]')       \n",
    "des = driver.find_elements_by_xpath('//table[@class=\"table table-striped\"]/tbody/tr/td[2]')\n",
    "\n",
    "for i in nam:\n",
    "    name.append(i.text)                 \n",
    "for j in des:\n",
    "    description.append(j.text)\n",
    "print(len(name))              \n",
    "print(len(description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3826a289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Description]\n",
       "Index: []"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame({'Name':name,'Description':description})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204ecf7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "062d15fc",
   "metadata": {},
   "source": [
    "*Q4. Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/ You have to find following details: A) Rank B) State C) GSDP D) GSDP E) Share F) GDP($ billion) Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "660cf345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-424b57198d19>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n",
      "<ipython-input-5-424b57198d19>:11: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  economy=driver.find_element_by_xpath(\"//div[@class='dropdown'][2]/div/a[3]\")\n",
      "<ipython-input-5-424b57198d19>:20: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  indian_states=driver.find_element_by_xpath(\"//ul[@style='list-style-type:none;margin-left:20px;']//li[1]/a\")\n",
      "<ipython-input-5-424b57198d19>:32: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  ranks=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[1]\")\n",
      "<ipython-input-5-424b57198d19>:43: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  states=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[2]\")\n",
      "<ipython-input-5-424b57198d19>:54: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  info=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[3]\")\n",
      "<ipython-input-5-424b57198d19>:64: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  info=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[4]\")\n",
      "<ipython-input-5-424b57198d19>:74: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  info=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[5]\")\n",
      "<ipython-input-5-424b57198d19>:84: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  info=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[6]\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP(Billion_$)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(19-20) GSDP(18-19) Share(18-19)  \\\n",
       "0     1                Maharashtra           -   2,632,792       13.94%   \n",
       "1     2                 Tamil Nadu   1,845,853   1,630,208        8.63%   \n",
       "2     3              Uttar Pradesh   1,687,818   1,584,764        8.39%   \n",
       "3     4                    Gujarat           -   1,502,899        7.96%   \n",
       "4     5                  Karnataka   1,631,977   1,493,127        7.91%   \n",
       "5     6                West Bengal   1,253,832   1,089,898        5.77%   \n",
       "6     7                  Rajasthan   1,020,989     942,586        4.99%   \n",
       "7     8             Andhra Pradesh     972,782     862,957        4.57%   \n",
       "8     9                  Telangana     969,604     861,031        4.56%   \n",
       "9    10             Madhya Pradesh     906,672     809,592        4.29%   \n",
       "10   11                     Kerala           -     781,653        4.14%   \n",
       "11   12                      Delhi     856,112     774,870        4.10%   \n",
       "12   13                    Haryana     831,610     734,163        3.89%   \n",
       "13   14                      Bihar     611,804     530,363        2.81%   \n",
       "14   15                     Punjab     574,760     526,376        2.79%   \n",
       "15   16                     Odisha     521,275     487,805        2.58%   \n",
       "16   17                      Assam           -     315,881        1.67%   \n",
       "17   18               Chhattisgarh     329,180     304,063        1.61%   \n",
       "18   19                  Jharkhand     328,598     297,204        1.57%   \n",
       "19   20                Uttarakhand           -     245,895        1.30%   \n",
       "20   21            Jammu & Kashmir           -     155,956        0.83%   \n",
       "21   22           Himachal Pradesh     165,472     153,845        0.81%   \n",
       "22   23                        Goa      80,449      73,170        0.39%   \n",
       "23   24                    Tripura      55,984      49,845        0.26%   \n",
       "24   25                 Chandigarh           -      42,114        0.22%   \n",
       "25   26                 Puducherry      38,253      34,433        0.18%   \n",
       "26   27                  Meghalaya      36,572      33,481        0.18%   \n",
       "27   28                     Sikkim      32,496      28,723        0.15%   \n",
       "28   29                    Manipur      31,790      27,870        0.15%   \n",
       "29   30                   Nagaland           -      27,283        0.14%   \n",
       "30   31          Arunachal Pradesh           -      24,603        0.13%   \n",
       "31   32                    Mizoram      26,503      22,287        0.12%   \n",
       "32   33  Andaman & Nicobar Islands           -           -            -   \n",
       "\n",
       "   GDP(Billion_$)  \n",
       "0         399.921  \n",
       "1         247.629  \n",
       "2         240.726  \n",
       "3         228.290  \n",
       "4         226.806  \n",
       "5         165.556  \n",
       "6         143.179  \n",
       "7         131.083  \n",
       "8         130.791  \n",
       "9         122.977  \n",
       "10        118.733  \n",
       "11        117.703  \n",
       "12        111.519  \n",
       "13         80.562  \n",
       "14         79.957  \n",
       "15         74.098  \n",
       "16         47.982  \n",
       "17         46.187  \n",
       "18         45.145  \n",
       "19         37.351  \n",
       "20         23.690  \n",
       "21         23.369  \n",
       "22         11.115  \n",
       "23          7.571  \n",
       "24          6.397  \n",
       "25          5.230  \n",
       "26          5.086  \n",
       "27          4.363  \n",
       "28          4.233  \n",
       "29          4.144  \n",
       "30          3.737  \n",
       "31          3.385  \n",
       "32              -  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(2)\n",
    "\n",
    "# Opening the statisticstimes.com\n",
    "url = \"http://statisticstimes.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "#clicking on economy button\n",
    "economy=driver.find_element_by_xpath(\"//div[@class='dropdown'][2]/div/a[3]\")\n",
    "try:\n",
    "    economy.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(economy.get_attribute('href'))\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#clicking on gdp of indian states\n",
    "indian_states=driver.find_element_by_xpath(\"//ul[@style='list-style-type:none;margin-left:20px;']//li[1]/a\")\n",
    "\n",
    "try:\n",
    "    indian_states.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(indian_states.get_attribute('href')) \n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#scraping rank\n",
    "rank=[]\n",
    "try:\n",
    "    ranks=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[1]\")\n",
    "    for i in ranks:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:                 #handling no such element exception\n",
    "    rank.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#scraping States\n",
    "State=[]\n",
    "try:\n",
    "    states=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[2]\")\n",
    "    for i in states:\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:                 #handling no such element exception\n",
    "    State.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#scraping GSDP\n",
    "GSDP_20=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[3]\")\n",
    "    for i in info:\n",
    "        GSDP_20.append(i.text)\n",
    "except NoSuchElementException:           #handling no such element exception\n",
    "    GSDP_20.append('No details available')\n",
    "time.sleep(2)    \n",
    "    \n",
    "#scraping GSDP\n",
    "GSDP_19=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[4]\")\n",
    "    for i in info:\n",
    "        GSDP_19.append(i.text)\n",
    "except NoSuchElementException:        #handling no such element exception\n",
    "    GSDP_19.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping share (18-19)\n",
    "share=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[5]\")\n",
    "    for i in info:\n",
    "        share.append(i.text)\n",
    "except NoSuchElementException:          #handling no such element exception\n",
    "    share.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping GDP(billion$)\n",
    "GDP_billion=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[6]\")\n",
    "    for i in info:\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:            #handling no such element exception\n",
    "    GDP_billion.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "#creatng dataframe\n",
    "df=pd.DataFrame({'Rank':rank,\n",
    "                'State':State,\n",
    "                'GSDP(19-20)':GSDP_20,\n",
    "                'GSDP(18-19)':GSDP_19,\n",
    "                'Share(18-19)':share,\n",
    "                'GDP(Billion_$)':GDP_billion})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bff75f",
   "metadata": {},
   "source": [
    "# Q5. Scrape the details of trending repositories on Github.com. Url = https://github.com/ You have to find the following details: A) Repository title B) Repository description C) Contributors count D) Language used Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e342240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url4 = 'https://github.com/'\n",
    "driver.get(url4)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5af8f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-89042fa51ec0>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  explore = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary')\n",
      "<ipython-input-22-89042fa51ec0>:4: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  trending = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul/li[5]/a')\n"
     ]
    }
   ],
   "source": [
    "explore = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary')\n",
    "explore.click()\n",
    "time.sleep(2)\n",
    "trending = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul/li[5]/a')\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f71adfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "title = []                \n",
    "description = []\n",
    "contributer = []\n",
    "\n",
    "soup=BeautifulSoup(driver.page_source,'html.parser')         \n",
    "t = soup.find_all('h1',attrs={'h3 lh-condensed'})\n",
    "d = soup.find_all('article',attrs={'Box-row'})\n",
    "c = soup.find_all('div',attrs={'f6 color-fg-muted mt-2'})\n",
    "\n",
    "for i in t:                                                 \n",
    "    try:                                                    \n",
    "        title.append(i.find('span').text.strip('\\n'))       \n",
    "    except AttributeError:\n",
    "        title.append(\"No details available\")\n",
    "for j in d:\n",
    "    try:\n",
    "        description.append(j.find('p').text.split('\\n')[-2])\n",
    "    except AttributeError:\n",
    "        description.append(\"No details available\")\n",
    "for k in c:\n",
    "    try:\n",
    "        contributer.append(k.find('a').text)\n",
    "    except AttributeError:\n",
    "        contributer.append(\"No details available\")\n",
    "\n",
    "print(len(title))                                      \n",
    "print(len(description))\n",
    "print(len(contributer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0361cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-205899d6e6f1>:3: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  links = driver.find_elements_by_xpath('//article[@class=\"Box-row\"]//h1//a')\n"
     ]
    }
   ],
   "source": [
    "urls = []                 \n",
    "\n",
    "links = driver.find_elements_by_xpath('//article[@class=\"Box-row\"]//h1//a')         \n",
    "\n",
    "for url in links:\n",
    "    urls.append(url.get_attribute('href'))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e28e4619",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-c7786a5609d5>:10: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  title = driver.find_element_by_xpath('//h1[@class=\" d-flex flex-wrap flex-items-center wb-break-word f3 text-normal\"]/span[1]')\n",
      "<ipython-input-25-c7786a5609d5>:17: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  descrip = driver.find_element_by_xpath('//div[@class=\"BorderGrid-cell\"]//p')\n",
      "<ipython-input-25-c7786a5609d5>:24: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  count = driver.find_element_by_xpath(\"//h2[@class='h4 mb-3']/a[contains(text(),'Contributors')]/span\")\n",
      "<ipython-input-25-c7786a5609d5>:31: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  lang = driver.find_element_by_xpath('//li[@class=\"d-inline\"]//a//span')\n"
     ]
    }
   ],
   "source": [
    "repository_title = []\n",
    "repository_description = []\n",
    "contributors_count = []\n",
    "language_used = []\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)                       \n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        title = driver.find_element_by_xpath('//h1[@class=\" d-flex flex-wrap flex-items-center wb-break-word f3 text-normal\"]/span[1]')\n",
    "        repository_title.append(title.text.replace('\\n',''))             \n",
    "    except NoSuchElementException:\n",
    "        repository_title.append('-')                         \n",
    "        \n",
    "    time.sleep(1)\n",
    "    try:\n",
    "        descrip = driver.find_element_by_xpath('//div[@class=\"BorderGrid-cell\"]//p')\n",
    "        repository_description.append(descrip.text.replace('\\n',''))\n",
    "    except NoSuchElementException:\n",
    "        repository_description.append('-')\n",
    "\n",
    "    time.sleep(1)\n",
    "    try:\n",
    "        count = driver.find_element_by_xpath(\"//h2[@class='h4 mb-3']/a[contains(text(),'Contributors')]/span\")\n",
    "        contributors_count.append(count.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        contributors_count.append('-')\n",
    "    time.sleep(1)\n",
    "    try:\n",
    "        lang = driver.find_element_by_xpath('//li[@class=\"d-inline\"]//a//span')\n",
    "        language_used.append(lang.text.replace('\\n',''))\n",
    "    except NoSuchElementException:\n",
    "        language_used.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83bdd5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repository_title</th>\n",
       "      <th>repository_description</th>\n",
       "      <th>contributors_count</th>\n",
       "      <th>language_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>Tool to scan for RouterOS (Mikrotik) forensic ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIAEvangelist</td>\n",
       "      <td>Inter Process Communication Module for node su...</td>\n",
       "      <td>35</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CodeEditApp</td>\n",
       "      <td>CodeEdit App for macOS – Elevate your code edi...</td>\n",
       "      <td>12</td>\n",
       "      <td>Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RanKKI</td>\n",
       "      <td>中华人民共和国法律手册</td>\n",
       "      <td>2</td>\n",
       "      <td>Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>public-apis</td>\n",
       "      <td>A collective list of free APIs</td>\n",
       "      <td>1,269</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lapce</td>\n",
       "      <td>Lightning-fast and Powerful Code Editor writte...</td>\n",
       "      <td>7</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>remix-run</td>\n",
       "      <td>The Remix Stack for deploying to Fly with Post...</td>\n",
       "      <td>4</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RIAEvangelist</td>\n",
       "      <td>-</td>\n",
       "      <td>6</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PowerShell</td>\n",
       "      <td>PowerShell for every system!</td>\n",
       "      <td>396</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>google</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PKUFlyingPig</td>\n",
       "      <td>计算机自学指南</td>\n",
       "      <td>22</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>freeCodeCamp</td>\n",
       "      <td>freeCodeCamp.org's open-source codebase and cu...</td>\n",
       "      <td>4,413</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>remix-run</td>\n",
       "      <td>The Remix Stack for deploying to Fly with SQLi...</td>\n",
       "      <td>5</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>psf</td>\n",
       "      <td>The uncompromising Python code formatter</td>\n",
       "      <td>312</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>drago-96</td>\n",
       "      <td>Proof of concept for CVE-2022-0778, which trig...</td>\n",
       "      <td>-</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>openmlsys</td>\n",
       "      <td>《Machine Learning Systems: Design and Implemen...</td>\n",
       "      <td>19</td>\n",
       "      <td>TeX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ploomber</td>\n",
       "      <td>The fastest ⚡️ way to build data pipelines. De...</td>\n",
       "      <td>33</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>discourse</td>\n",
       "      <td>A platform for community discussion. Free, ope...</td>\n",
       "      <td>806</td>\n",
       "      <td>Ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gothinkster</td>\n",
       "      <td>\"The mother of all demo apps\" — Exemplary full...</td>\n",
       "      <td>73</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jackfrued</td>\n",
       "      <td>Python - 100天从新手到大师</td>\n",
       "      <td>12</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>iperov</td>\n",
       "      <td>Real-time face swap for PC streaming or video ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>yewstack</td>\n",
       "      <td>Rust / Wasm framework for building client web ...</td>\n",
       "      <td>297</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Teaching-Assistants-of-Cloud-Computing</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ToolJet</td>\n",
       "      <td>Extensible low-code framework for building bus...</td>\n",
       "      <td>132</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>chen310</td>\n",
       "      <td>网易云音乐自动任务：刷等级、云贝、云豆等</td>\n",
       "      <td>7</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          repository_title  \\\n",
       "0                                microsoft   \n",
       "1                            RIAEvangelist   \n",
       "2                              CodeEditApp   \n",
       "3                                   RanKKI   \n",
       "4                              public-apis   \n",
       "5                                    lapce   \n",
       "6                                remix-run   \n",
       "7                            RIAEvangelist   \n",
       "8                               PowerShell   \n",
       "9                                   google   \n",
       "10                            PKUFlyingPig   \n",
       "11                            freeCodeCamp   \n",
       "12                               remix-run   \n",
       "13                                     psf   \n",
       "14                                drago-96   \n",
       "15                               openmlsys   \n",
       "16                                ploomber   \n",
       "17                               discourse   \n",
       "18                             gothinkster   \n",
       "19                               jackfrued   \n",
       "20                                  iperov   \n",
       "21                                yewstack   \n",
       "22  Teaching-Assistants-of-Cloud-Computing   \n",
       "23                                 ToolJet   \n",
       "24                                 chen310   \n",
       "\n",
       "                               repository_description contributors_count  \\\n",
       "0   Tool to scan for RouterOS (Mikrotik) forensic ...                  3   \n",
       "1   Inter Process Communication Module for node su...                 35   \n",
       "2   CodeEdit App for macOS – Elevate your code edi...                 12   \n",
       "3                                         中华人民共和国法律手册                  2   \n",
       "4                      A collective list of free APIs              1,269   \n",
       "5   Lightning-fast and Powerful Code Editor writte...                  7   \n",
       "6   The Remix Stack for deploying to Fly with Post...                  4   \n",
       "7                                                   -                  6   \n",
       "8                        PowerShell for every system!                396   \n",
       "9                                                   -                  -   \n",
       "10                                            计算机自学指南                 22   \n",
       "11  freeCodeCamp.org's open-source codebase and cu...              4,413   \n",
       "12  The Remix Stack for deploying to Fly with SQLi...                  5   \n",
       "13           The uncompromising Python code formatter                312   \n",
       "14  Proof of concept for CVE-2022-0778, which trig...                  -   \n",
       "15  《Machine Learning Systems: Design and Implemen...                 19   \n",
       "16  The fastest ⚡️ way to build data pipelines. De...                 33   \n",
       "17  A platform for community discussion. Free, ope...                806   \n",
       "18  \"The mother of all demo apps\" — Exemplary full...                 73   \n",
       "19                                Python - 100天从新手到大师                 12   \n",
       "20  Real-time face swap for PC streaming or video ...                  4   \n",
       "21  Rust / Wasm framework for building client web ...                297   \n",
       "22                                                  -                  4   \n",
       "23  Extensible low-code framework for building bus...                132   \n",
       "24                               网易云音乐自动任务：刷等级、云贝、云豆等                  7   \n",
       "\n",
       "   language_used  \n",
       "0         Python  \n",
       "1     JavaScript  \n",
       "2          Swift  \n",
       "3          Swift  \n",
       "4         Python  \n",
       "5           Rust  \n",
       "6     TypeScript  \n",
       "7     JavaScript  \n",
       "8             C#  \n",
       "9              -  \n",
       "10             -  \n",
       "11    JavaScript  \n",
       "12    TypeScript  \n",
       "13        Python  \n",
       "14             C  \n",
       "15           TeX  \n",
       "16        Python  \n",
       "17          Ruby  \n",
       "18         Shell  \n",
       "19        Python  \n",
       "20        Python  \n",
       "21          Rust  \n",
       "22          HTML  \n",
       "23    JavaScript  \n",
       "24        Python  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github = pd.DataFrame({})\n",
    "github['repository_title'] = repository_title\n",
    "github['repository_description'] = repository_description\n",
    "github['contributors_count']  = contributors_count\n",
    "github['language_used'] = language_used\n",
    "github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390a3c58",
   "metadata": {},
   "source": [
    "Q6. Scrape the details of top 100 songs on billboard.com. Url = https://www.billboard.com/ You have to find the following details: A) Song name B) Artist name C) Last week rank D) Peak rank E) Weeks on board Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b31b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url5 = 'https:/www.billboard.com/'\n",
    "driver.get(url5)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07b9b255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-adfd9faea3ea>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  hot = driver.find_element_by_xpath('//div[@class=\"lrv-u-flex lrv-u-background-color-white u-height-45\"]//li[1]')\n"
     ]
    }
   ],
   "source": [
    "hot = driver.find_element_by_xpath('//div[@class=\"lrv-u-flex lrv-u-background-color-white u-height-45\"]//li[1]')\n",
    "hot.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fe5bced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-f25fcc99928c>:7: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  song = driver.find_elements_by_xpath('//li[@class=\"lrv-u-width-100p\"]//h3')\n",
      "<ipython-input-36-f25fcc99928c>:8: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  art = driver.find_elements_by_xpath('//li[@class=\"lrv-u-width-100p\"]/ul/li[1]//span[1]')\n",
      "<ipython-input-36-f25fcc99928c>:9: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  las = driver.find_elements_by_xpath('//li[@class=\"lrv-u-width-100p\"]/ul/li[4]')\n",
      "<ipython-input-36-f25fcc99928c>:10: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  pea = driver.find_elements_by_xpath('//li[@class=\"lrv-u-width-100p\"]/ul/li[5]')\n",
      "<ipython-input-36-f25fcc99928c>:11: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  boa = driver.find_elements_by_xpath('//li[@class=\"lrv-u-width-100p\"]/ul/li[6]')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "songs = []       \n",
    "artists = []\n",
    "last = []\n",
    "peak = []\n",
    "board = []\n",
    "\n",
    "song = driver.find_elements_by_xpath('//li[@class=\"lrv-u-width-100p\"]//h3')   \n",
    "art = driver.find_elements_by_xpath('//li[@class=\"lrv-u-width-100p\"]/ul/li[1]//span[1]')\n",
    "las = driver.find_elements_by_xpath('//li[@class=\"lrv-u-width-100p\"]/ul/li[4]')\n",
    "pea = driver.find_elements_by_xpath('//li[@class=\"lrv-u-width-100p\"]/ul/li[5]')\n",
    "boa = driver.find_elements_by_xpath('//li[@class=\"lrv-u-width-100p\"]/ul/li[6]')\n",
    "\n",
    "for i in song:\n",
    "    songs.append(i.text)\n",
    "for j in art:\n",
    "    artists.append(j.text)\n",
    "for k in las:\n",
    "    last.append(k.text)\n",
    "for l in pea:\n",
    "    peak.append(l.text)\n",
    "for m in boa:\n",
    "    board.append(m.text)\n",
    "\n",
    "print(len(songs))       \n",
    "print(len(artists))\n",
    "print(len(last))\n",
    "print(len(peak))\n",
    "print(len(board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2e4ae92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Songs</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Heat Waves</td>\n",
       "      <td>Glass Animals</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We Don't Talk About Bruno</td>\n",
       "      <td>Carolina Gaitan, Mauro Castillo, Adassa, Rhenz...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Super Gremlin</td>\n",
       "      <td>Kodak Black</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abcdefu</td>\n",
       "      <td>GAYLE</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stay</td>\n",
       "      <td>The Kid LAROI &amp; Justin Bieber</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Evil Twins</td>\n",
       "      <td>King Von &amp; Lil Durk</td>\n",
       "      <td>-</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Trust Nothing</td>\n",
       "      <td>King Von Featuring Moneybagg Yo</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Iffy</td>\n",
       "      <td>Chris Brown</td>\n",
       "      <td>92</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Closer</td>\n",
       "      <td>Saweetie Featuring H.E.R.</td>\n",
       "      <td>98</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>When I'm Gone</td>\n",
       "      <td>Alesso / Katy Perry</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Songs  \\\n",
       "0                  Heat Waves   \n",
       "1   We Don't Talk About Bruno   \n",
       "2               Super Gremlin   \n",
       "3                     abcdefu   \n",
       "4                        Stay   \n",
       "..                        ...   \n",
       "95                 Evil Twins   \n",
       "96              Trust Nothing   \n",
       "97                       Iffy   \n",
       "98                     Closer   \n",
       "99              When I'm Gone   \n",
       "\n",
       "                                               Artist Last Week Rank  \\\n",
       "0                                       Glass Animals              1   \n",
       "1   Carolina Gaitan, Mauro Castillo, Adassa, Rhenz...              2   \n",
       "2                                         Kodak Black              4   \n",
       "3                                               GAYLE              3   \n",
       "4                       The Kid LAROI & Justin Bieber              5   \n",
       "..                                                ...            ...   \n",
       "95                                King Von & Lil Durk              -   \n",
       "96                    King Von Featuring Moneybagg Yo              -   \n",
       "97                                        Chris Brown             92   \n",
       "98                          Saweetie Featuring H.E.R.             98   \n",
       "99                                Alesso / Katy Perry             91   \n",
       "\n",
       "   Peak rank Weeks on board  \n",
       "0          1             60  \n",
       "1          1             11  \n",
       "2          3             18  \n",
       "3          3             16  \n",
       "4          1             35  \n",
       "..       ...            ...  \n",
       "95        96              1  \n",
       "96        97              1  \n",
       "97        71              8  \n",
       "98        89              4  \n",
       "99        90              4  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = pd.DataFrame({'Songs':songs,\n",
    "                   'Artist':artists,\n",
    "                   'Last Week Rank':last,\n",
    "                   'Peak rank':peak,\n",
    "                   'Weeks on board':board})\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b189b2f",
   "metadata": {},
   "source": [
    "Q7. Scrape the details of Data science recruiters from naukri.com. Url = https://www.naukri.com/ You have to find the following details: A) Name B) Designation C) Company D) Skills they hire for E) Location Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c44d4bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-a0e267e0d536>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6373a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "url6 = 'https://www.naukri.com'\n",
    "driver.get(url6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "888e79e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-1b923390f017>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search = driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[1]/div/div/div/input')\n"
     ]
    }
   ],
   "source": [
    "search = driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[1]/div/div/div/input')\n",
    "search.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec8886e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-8206ef8fdc3e>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  click = driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n"
     ]
    }
   ],
   "source": [
    "click = driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "517d9ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-7f97855e80e7>:1: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  urls=[i.get_attribute(\"href\")for i in driver.find_elements_by_xpath(\"//a[@title='Search Recruiters']\")]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/recruiters']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls=[i.get_attribute(\"href\")for i in driver.find_elements_by_xpath(\"//a[@title='Search Recruiters']\")]\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "712a68a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-bb7659657f49>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search = driver.find_element_by_xpath('//*[@id=\"skill\"]/div[1]/div[2]/input')\n",
      "<ipython-input-43-bb7659657f49>:5: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  searchh = driver.find_element_by_xpath('//*[@id=\"qsbFormBtn\"]')\n"
     ]
    }
   ],
   "source": [
    "search = driver.find_element_by_xpath('//*[@id=\"skill\"]/div[1]/div[2]/input') \n",
    "search.clear()\n",
    "search.send_keys('Data Scientist')      \n",
    "time.sleep(2)\n",
    "searchh = driver.find_element_by_xpath('//*[@id=\"qsbFormBtn\"]')  \n",
    "searchh.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52ad2fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-44-d48ad91767a4>:6: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  nam = driver.find_elements_by_xpath('//div[@class=\"recInfo\"]/div[1]/p/a/span')\n",
      "<ipython-input-44-d48ad91767a4>:7: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  desi = driver.find_elements_by_xpath('//div[@class=\"recInfo\"]/div[1]/p/span[1]')\n",
      "<ipython-input-44-d48ad91767a4>:8: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  comp = driver.find_elements_by_xpath('//div[@class=\"recInfo\"]/div[1]/p/a[2]')\n",
      "<ipython-input-44-d48ad91767a4>:9: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  skill = driver.find_elements_by_xpath('//div[@class=\"recInfo\"]/div[2]')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "name = []           \n",
    "designation = [] \n",
    "company = []\n",
    "skills = []\n",
    "\n",
    "nam = driver.find_elements_by_xpath('//div[@class=\"recInfo\"]/div[1]/p/a/span')     \n",
    "desi = driver.find_elements_by_xpath('//div[@class=\"recInfo\"]/div[1]/p/span[1]')\n",
    "comp = driver.find_elements_by_xpath('//div[@class=\"recInfo\"]/div[1]/p/a[2]')\n",
    "skill = driver.find_elements_by_xpath('//div[@class=\"recInfo\"]/div[2]')\n",
    "\n",
    "for i in nam:                  \n",
    "    name.append(i.text)                                 \n",
    "for j in desi:\n",
    "    designation.append(j.text)\n",
    "for k in comp:\n",
    "    company.append(k.text)\n",
    "for n in skill:\n",
    "    skills.append(n.text)\n",
    "\n",
    "print(len(name))                               \n",
    "print(len(designation))\n",
    "print(len(company))\n",
    "print(len(skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2692fd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "location=[]            \n",
    "soup=BeautifulSoup(driver.page_source,'html.parser')      \n",
    "l=soup.find_all('div',attrs={'vcard'})                    \n",
    "for i in l:\n",
    "    try:                                         \n",
    "        location.append(i.find('small').text)             \n",
    "    except AttributeError :\n",
    "        location.append(\"No details available\")\n",
    "print(len(location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b51e2389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills Needed</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tanushree</td>\n",
       "      <td>Lead Recruiter</td>\n",
       "      <td>RecRoots</td>\n",
       "      <td>UI Developers, Software Engineers, Quality Ass...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sashi bhushan</td>\n",
       "      <td>Senior Specialist</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>pig, hbase, sas, spss, apache, python, nosql, ...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bitapi</td>\n",
       "      <td>HR and Operation Manager</td>\n",
       "      <td>Anvaya</td>\n",
       "      <td>Hadoop, Big Data, Data Scientists, Java, Sprin...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gajendra Singh</td>\n",
       "      <td>Head of Recruitment - Product &amp;amp;...</td>\n",
       "      <td>A Leading of Product Start-UP Company</td>\n",
       "      <td>Data Scientist, Big Data, Hadoop, Web Analytic...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sadashiv Kulkarni</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Digitially Insights Pvt Ltd</td>\n",
       "      <td>Big Data Engineer, Data Scientist, Solutions, ...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Invelopment</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Invelopment</td>\n",
       "      <td>Scandinavian Startups</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Anjali Srivastava</td>\n",
       "      <td>Director HR</td>\n",
       "      <td>CodeFire Technologies Pvt. Ltd.</td>\n",
       "      <td>Technical, Business Development Executive, Sof...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Helly Vyas</td>\n",
       "      <td>HR Business Partner</td>\n",
       "      <td>AM - TA &amp;amp; HR</td>\n",
       "      <td>Big Data technology, PLSQL, Web Developer, Jav...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ashish Verma</td>\n",
       "      <td>Senior Associate Human Resources</td>\n",
       "      <td>Evalueserve.com Private Limited</td>\n",
       "      <td>SAS, VBA, Business Information Services(BIS), ...</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shiva Kumar N</td>\n",
       "      <td>Founder</td>\n",
       "      <td>Rapid Talent Solutions -9148242334</td>\n",
       "      <td>salaesforce, Web Technologies, .net, .net full...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Balaji Prabhakaran</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Oportun</td>\n",
       "      <td>Technical Solution Architect, Data Scientist, ...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bhuwneshari Devi</td>\n",
       "      <td>Lead Talent Acquisition</td>\n",
       "      <td>Success Pact Consulting</td>\n",
       "      <td>Amazon, Olacabs, Quikr, Bankbazzar, Uber, Flip...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HS Sandesh</td>\n",
       "      <td>Talent Evangelist www staffiohr co</td>\n",
       "      <td>Staffio HR</td>\n",
       "      <td>Digital Marketing, General Manager, Business D...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Anoop Somarajan</td>\n",
       "      <td>Manager - Talent Acquisition</td>\n",
       "      <td>R1RCM</td>\n",
       "      <td>Asp.net, Hl7, Mirth, Perl, Xamarin, Javascript...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Datafoundry</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>JAITRA SOFTWARE SOLUTIONS PVT LTD</td>\n",
       "      <td>Webmethods Developer, Mean Stack, Business Ana...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A Valsa Florina</td>\n",
       "      <td>Recruitment Specialist</td>\n",
       "      <td>Redbus.in</td>\n",
       "      <td>Business Analyst, Front end developer, legal, ...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kalaivani M V</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>ZYUDLY LABS DATA SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Data Scientist, Cloud Computing, Mobile Applic...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Prashant K</td>\n",
       "      <td>Sr HR</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Data Analyst, Statistical Analysis, Data Scien...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Radhika</td>\n",
       "      <td>HR Associate</td>\n",
       "      <td>Bright Bridge Info-tech Pvt Ltd</td>\n",
       "      <td>business analyst - IT (python), pay per click,...</td>\n",
       "      <td>Coimbatore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rakhi</td>\n",
       "      <td>HR recruiter</td>\n",
       "      <td>Constalytics</td>\n",
       "      <td>Data Scientist, Data Research Analyst, Big Dat...</td>\n",
       "      <td>Singapore - (singapore)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Monika Jain</td>\n",
       "      <td>Talent Aquistion Lead</td>\n",
       "      <td>Info Edge India Limited</td>\n",
       "      <td>Lamp Developer, Ui/ux Developer, Qa Engineer, ...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Trilok Nath</td>\n",
       "      <td>Senior IT Recruiter</td>\n",
       "      <td>Molveno Consulting Private Limited</td>\n",
       "      <td>.Net Developers With Angular Js, Html, Front E...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Rashmi Kathuria</td>\n",
       "      <td>Talent Acquisition Specialist (Specialized...</td>\n",
       "      <td>Mount Talent consulting</td>\n",
       "      <td>Leading MNCs, Product based organizations</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Vidya Rani Hadimani</td>\n",
       "      <td>Business Manager Delivery</td>\n",
       "      <td>Talent Management Labs Inc.</td>\n",
       "      <td>Amazon Walmart Adobe OLA Myntracom Komli Media...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Monika Singh Thakur</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>ValueLabs</td>\n",
       "      <td>Big Data Analytics, Marketing Analytics, Full ...</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ankit Soni</td>\n",
       "      <td>Talent Acquisition</td>\n",
       "      <td>Seven N Half</td>\n",
       "      <td>Relationship Management, Branch Management, Br...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Shikha Bakshi</td>\n",
       "      <td>Senior Manager Recruitment</td>\n",
       "      <td>Fractal Analytics!!</td>\n",
       "      <td>Analytics, Big Data, Hadoop, Python</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd</td>\n",
       "      <td>Data Analytics, Managed Services, Team Leading...</td>\n",
       "      <td>Mysoru / Mysore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ravi</td>\n",
       "      <td>Team HR</td>\n",
       "      <td>Einfluss Teknocommercial Pvt. Ltd.</td>\n",
       "      <td>Deep Learning, Machine Learning, unstructured ...</td>\n",
       "      <td>Ghaziabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Ishu Kumar</td>\n",
       "      <td>Co Founder &amp;amp; Ceo</td>\n",
       "      <td>Data X</td>\n",
       "      <td>Python, Machine Learning, Sql, Data Science</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Vivek Shrivastava</td>\n",
       "      <td>Assistant Manager Human Resources</td>\n",
       "      <td>InnovAccer Management Pvt Ltd</td>\n",
       "      <td>Business Analyst, analytics, Decesion Scientis...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Gayathri E</td>\n",
       "      <td>Sr Recruitment</td>\n",
       "      <td>Wonderwrks IT Services Private Limited</td>\n",
       "      <td>IT Infrastructure Management, PHP, Wordpress, ...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Best In Town Analytics</td>\n",
       "      <td>Analytics Associate</td>\n",
       "      <td>BITA</td>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Nagendla Syam Kumar</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>FLOWERHORN IT PVT LTD</td>\n",
       "      <td>Machine Learning, NLP, Performance Review, HR,...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Santhosh Nagaiah</td>\n",
       "      <td>Chief marketing officer</td>\n",
       "      <td>Tuple Technologies Pte Ltd</td>\n",
       "      <td>Data Science, Project Management, Backend</td>\n",
       "      <td>No details available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>priyanka</td>\n",
       "      <td>General Manager</td>\n",
       "      <td>Reliance Industries</td>\n",
       "      <td>Sap, Saas, Sql, Hadoop, Production Planning, B...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Renny Benita K</td>\n",
       "      <td>Operations Manager</td>\n",
       "      <td>DeepIQ Software Solutions Pvt Ltd</td>\n",
       "      <td>Core Java, J2ee, Big Data, Machine Learning, D...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Sudipta Samanta</td>\n",
       "      <td>Founder</td>\n",
       "      <td>DataNnoviteSol LLP</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Roshan Menugu</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Cyient Limited</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>HR Team</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Terra Blue Exploration Technologies Pvt....</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Jamil Akhtar</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Quikkloan</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>rajesh</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>quantum value IT services</td>\n",
       "      <td>Data Scientist, Tableau, R Tool, Data Analytic...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>navya neluri</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>asens labs</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ram Kumar</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Working As A Freelancer</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Shreya Naithani</td>\n",
       "      <td>Talent Acquisition Executive</td>\n",
       "      <td>Purplejack Labs Pvt. Ltd.</td>\n",
       "      <td>Node.js, React.js, Etl Testing, Data Warehousi...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Vanitha Senkurichi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Quaero 3 India Ltd</td>\n",
       "      <td>sql, Ui Development, ssis, Data Modeling, Data...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Sravan Kumar Ranga</td>\n",
       "      <td>Assistant Manager</td>\n",
       "      <td>GSPANN Technologies</td>\n",
       "      <td>devops, build and release, Delivery Manager, O...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Zack</td>\n",
       "      <td>Recruitment Manager</td>\n",
       "      <td>Perex Engineering Pvt Ltd</td>\n",
       "      <td>Software Development, Javascript, Core Java, J...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Priyanka Akiri</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Infinitive Software Solutions</td>\n",
       "      <td>Oracle Dba, Data Science, Data Warehousing, ET...</td>\n",
       "      <td>Hyderabad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name  \\\n",
       "0                                      Tanushree   \n",
       "1                                  sashi bhushan   \n",
       "2                                         Bitapi   \n",
       "3                                 Gajendra Singh   \n",
       "4                              Sadashiv Kulkarni   \n",
       "5                                    Invelopment   \n",
       "6                              Anjali Srivastava   \n",
       "7                                     Helly Vyas   \n",
       "8                                   Ashish Verma   \n",
       "9                                  Shiva Kumar N   \n",
       "10                            Balaji Prabhakaran   \n",
       "11                              Bhuwneshari Devi   \n",
       "12                                    HS Sandesh   \n",
       "13                               Anoop Somarajan   \n",
       "14                                   Datafoundry   \n",
       "15                               A Valsa Florina   \n",
       "16                                 Kalaivani M V   \n",
       "17                                    Prashant K   \n",
       "18                                       Radhika   \n",
       "19                                         Rakhi   \n",
       "20                                   Monika Jain   \n",
       "21                                   Trilok Nath   \n",
       "22                               Rashmi Kathuria   \n",
       "23                           Vidya Rani Hadimani   \n",
       "24                           Monika Singh Thakur   \n",
       "25                                    Ankit Soni   \n",
       "26                                 Shikha Bakshi   \n",
       "27  Abhishek - Only Analytics Hiring - India and   \n",
       "28                                     Jayanth N   \n",
       "29                                          Ravi   \n",
       "30                                    Ishu Kumar   \n",
       "31                             Vivek Shrivastava   \n",
       "32                                    Gayathri E   \n",
       "33                        Best In Town Analytics   \n",
       "34                           Nagendla Syam Kumar   \n",
       "35                              Santhosh Nagaiah   \n",
       "36                                      priyanka   \n",
       "37                                Renny Benita K   \n",
       "38                               Sudipta Samanta   \n",
       "39                                 Roshan Menugu   \n",
       "40                                       HR Team   \n",
       "41                                  Jamil Akhtar   \n",
       "42                                        rajesh   \n",
       "43                                  navya neluri   \n",
       "44                                     Ram Kumar   \n",
       "45                               Shreya Naithani   \n",
       "46                            Vanitha Senkurichi   \n",
       "47                            Sravan Kumar Ranga   \n",
       "48                                          Zack   \n",
       "49                                Priyanka Akiri   \n",
       "\n",
       "                                      Designation  \\\n",
       "0                                  Lead Recruiter   \n",
       "1                               Senior Specialist   \n",
       "2                        HR and Operation Manager   \n",
       "3          Head of Recruitment - Product &amp;...   \n",
       "4                                      Company HR   \n",
       "5                                      Company HR   \n",
       "6                                     Director HR   \n",
       "7                             HR Business Partner   \n",
       "8                Senior Associate Human Resources   \n",
       "9                                         Founder   \n",
       "10                              Company Recruiter   \n",
       "11                        Lead Talent Acquisition   \n",
       "12             Talent Evangelist www staffiohr co   \n",
       "13                   Manager - Talent Acquisition   \n",
       "14                                     Company HR   \n",
       "15                         Recruitment Specialist   \n",
       "16                                     HR Manager   \n",
       "17                                          Sr HR   \n",
       "18                                   HR Associate   \n",
       "19                                   HR recruiter   \n",
       "20                          Talent Aquistion Lead   \n",
       "21                            Senior IT Recruiter   \n",
       "22  Talent Acquisition Specialist (Specialized...   \n",
       "23                      Business Manager Delivery   \n",
       "24                            Technical Recruiter   \n",
       "25                             Talent Acquisition   \n",
       "26                     Senior Manager Recruitment   \n",
       "27                    Recruitment Lead Consultant   \n",
       "28                                Project Manager   \n",
       "29                                        Team HR   \n",
       "30                           Co Founder &amp; Ceo   \n",
       "31              Assistant Manager Human Resources   \n",
       "32                                 Sr Recruitment   \n",
       "33                            Analytics Associate   \n",
       "34                                 Data Scientist   \n",
       "35                        Chief marketing officer   \n",
       "36                                General Manager   \n",
       "37                             Operations Manager   \n",
       "38                                        Founder   \n",
       "39                              Company Recruiter   \n",
       "40                                     Company HR   \n",
       "41                              Company Recruiter   \n",
       "42                                   HR Executive   \n",
       "43                                 Data Scientist   \n",
       "44                                 Data Scientist   \n",
       "45                   Talent Acquisition Executive   \n",
       "46                                     Company HR   \n",
       "47                              Assistant Manager   \n",
       "48                            Recruitment Manager   \n",
       "49                                     HR Manager   \n",
       "\n",
       "                                        Company  \\\n",
       "0                                      RecRoots   \n",
       "1                                         Wipro   \n",
       "2                                        Anvaya   \n",
       "3         A Leading of Product Start-UP Company   \n",
       "4                   Digitially Insights Pvt Ltd   \n",
       "5                                   Invelopment   \n",
       "6               CodeFire Technologies Pvt. Ltd.   \n",
       "7                              AM - TA &amp; HR   \n",
       "8               Evalueserve.com Private Limited   \n",
       "9            Rapid Talent Solutions -9148242334   \n",
       "10                                      Oportun   \n",
       "11                      Success Pact Consulting   \n",
       "12                                   Staffio HR   \n",
       "13                                        R1RCM   \n",
       "14            JAITRA SOFTWARE SOLUTIONS PVT LTD   \n",
       "15                                    Redbus.in   \n",
       "16   ZYUDLY LABS DATA SOLUTIONS PRIVATE LIMITED   \n",
       "17                                 Confidential   \n",
       "18              Bright Bridge Info-tech Pvt Ltd   \n",
       "19                                 Constalytics   \n",
       "20                      Info Edge India Limited   \n",
       "21           Molveno Consulting Private Limited   \n",
       "22                      Mount Talent consulting   \n",
       "23                  Talent Management Labs Inc.   \n",
       "24                                    ValueLabs   \n",
       "25                                 Seven N Half   \n",
       "26                          Fractal Analytics!!   \n",
       "27   Apidel Technologies Division of Transpower   \n",
       "28     Dollarbird Information Services Pvt, Ltd   \n",
       "29           Einfluss Teknocommercial Pvt. Ltd.   \n",
       "30                                       Data X   \n",
       "31                InnovAccer Management Pvt Ltd   \n",
       "32       Wonderwrks IT Services Private Limited   \n",
       "33                                         BITA   \n",
       "34                        FLOWERHORN IT PVT LTD   \n",
       "35                   Tuple Technologies Pte Ltd   \n",
       "36                          Reliance Industries   \n",
       "37            DeepIQ Software Solutions Pvt Ltd   \n",
       "38                           DataNnoviteSol LLP   \n",
       "39                               Cyient Limited   \n",
       "40  Terra Blue Exploration Technologies Pvt....   \n",
       "41                                    Quikkloan   \n",
       "42                    quantum value IT services   \n",
       "43                                   asens labs   \n",
       "44                      Working As A Freelancer   \n",
       "45                    Purplejack Labs Pvt. Ltd.   \n",
       "46                           Quaero 3 India Ltd   \n",
       "47                          GSPANN Technologies   \n",
       "48                    Perex Engineering Pvt Ltd   \n",
       "49                Infinitive Software Solutions   \n",
       "\n",
       "                                        Skills Needed  \\\n",
       "0   UI Developers, Software Engineers, Quality Ass...   \n",
       "1   pig, hbase, sas, spss, apache, python, nosql, ...   \n",
       "2   Hadoop, Big Data, Data Scientists, Java, Sprin...   \n",
       "3   Data Scientist, Big Data, Hadoop, Web Analytic...   \n",
       "4   Big Data Engineer, Data Scientist, Solutions, ...   \n",
       "5                               Scandinavian Startups   \n",
       "6   Technical, Business Development Executive, Sof...   \n",
       "7   Big Data technology, PLSQL, Web Developer, Jav...   \n",
       "8   SAS, VBA, Business Information Services(BIS), ...   \n",
       "9   salaesforce, Web Technologies, .net, .net full...   \n",
       "10  Technical Solution Architect, Data Scientist, ...   \n",
       "11  Amazon, Olacabs, Quikr, Bankbazzar, Uber, Flip...   \n",
       "12  Digital Marketing, General Manager, Business D...   \n",
       "13  Asp.net, Hl7, Mirth, Perl, Xamarin, Javascript...   \n",
       "14  Webmethods Developer, Mean Stack, Business Ana...   \n",
       "15  Business Analyst, Front end developer, legal, ...   \n",
       "16  Data Scientist, Cloud Computing, Mobile Applic...   \n",
       "17  Data Analyst, Statistical Analysis, Data Scien...   \n",
       "18  business analyst - IT (python), pay per click,...   \n",
       "19  Data Scientist, Data Research Analyst, Big Dat...   \n",
       "20  Lamp Developer, Ui/ux Developer, Qa Engineer, ...   \n",
       "21  .Net Developers With Angular Js, Html, Front E...   \n",
       "22          Leading MNCs, Product based organizations   \n",
       "23  Amazon Walmart Adobe OLA Myntracom Komli Media...   \n",
       "24  Big Data Analytics, Marketing Analytics, Full ...   \n",
       "25  Relationship Management, Branch Management, Br...   \n",
       "26                Analytics, Big Data, Hadoop, Python   \n",
       "27  Analytics, Business Intelligence, Business Ana...   \n",
       "28  Data Analytics, Managed Services, Team Leading...   \n",
       "29  Deep Learning, Machine Learning, unstructured ...   \n",
       "30        Python, Machine Learning, Sql, Data Science   \n",
       "31  Business Analyst, analytics, Decesion Scientis...   \n",
       "32  IT Infrastructure Management, PHP, Wordpress, ...   \n",
       "33                                     Data Analytics   \n",
       "34  Machine Learning, NLP, Performance Review, HR,...   \n",
       "35          Data Science, Project Management, Backend   \n",
       "36  Sap, Saas, Sql, Hadoop, Production Planning, B...   \n",
       "37  Core Java, J2ee, Big Data, Machine Learning, D...   \n",
       "38                                      Not Specified   \n",
       "39                                      Not Specified   \n",
       "40                                      Not Specified   \n",
       "41                                      Not Specified   \n",
       "42  Data Scientist, Tableau, R Tool, Data Analytic...   \n",
       "43                                      Not Specified   \n",
       "44                                      Not Specified   \n",
       "45  Node.js, React.js, Etl Testing, Data Warehousi...   \n",
       "46  sql, Ui Development, ssis, Data Modeling, Data...   \n",
       "47  devops, build and release, Delivery Manager, O...   \n",
       "48  Software Development, Javascript, Core Java, J...   \n",
       "49  Oracle Dba, Data Science, Data Warehousing, ET...   \n",
       "\n",
       "                    Location  \n",
       "0                      Noida  \n",
       "1      Bengaluru / Bangalore  \n",
       "2      Bengaluru / Bangalore  \n",
       "3                      Noida  \n",
       "4                       Pune  \n",
       "5                  Ahmedabad  \n",
       "6                      Noida  \n",
       "7                       Pune  \n",
       "8                    Gurgaon  \n",
       "9      Bengaluru / Bangalore  \n",
       "10                   Chennai  \n",
       "11                     Delhi  \n",
       "12     Bengaluru / Bangalore  \n",
       "13                   Chennai  \n",
       "14     Bengaluru / Bangalore  \n",
       "15     Bengaluru / Bangalore  \n",
       "16                   Chennai  \n",
       "17     Bengaluru / Bangalore  \n",
       "18                Coimbatore  \n",
       "19   Singapore - (singapore)  \n",
       "20                     Noida  \n",
       "21  Hyderabad / Secunderabad  \n",
       "22                     Noida  \n",
       "23     Bengaluru / Bangalore  \n",
       "24                    Indore  \n",
       "25                 Ahmedabad  \n",
       "26                   Gurgaon  \n",
       "27         Vadodara / Baroda  \n",
       "28           Mysoru / Mysore  \n",
       "29                 Ghaziabad  \n",
       "30     Bengaluru / Bangalore  \n",
       "31                     Noida  \n",
       "32                   Chennai  \n",
       "33     Bengaluru / Bangalore  \n",
       "34     Bengaluru / Bangalore  \n",
       "35      No details available  \n",
       "36                    Mumbai  \n",
       "37     Bengaluru / Bangalore  \n",
       "38                      Pune  \n",
       "39  Hyderabad / Secunderabad  \n",
       "40     Bengaluru / Bangalore  \n",
       "41                     Delhi  \n",
       "42     Bengaluru / Bangalore  \n",
       "43  Hyderabad / Secunderabad  \n",
       "44                      Pune  \n",
       "45                    Mumbai  \n",
       "46     Bengaluru / Bangalore  \n",
       "47  Hyderabad / Secunderabad  \n",
       "48  Hyderabad / Secunderabad  \n",
       "49                 Hyderabad  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7 = pd.DataFrame({'Name':name,\n",
    "                   'Designation':designation,\n",
    "                   'Company':company,\n",
    "                   'Skills Needed':skills,\n",
    "                   'Location':location})\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f069459",
   "metadata": {},
   "source": [
    "Q8. Scrape the details of Highest selling novels. Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare/ You have to find the following details: A) Book name B) Author name C) Volumes sold D) Publisher E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "974c0e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-dd9f7bdb06f3>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n",
      "<ipython-input-14-dd9f7bdb06f3>:13: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  names=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[2]\")\n",
      "<ipython-input-14-dd9f7bdb06f3>:23: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  names=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[3]\")\n",
      "<ipython-input-14-dd9f7bdb06f3>:34: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  sale=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[4]\")\n",
      "<ipython-input-14-dd9f7bdb06f3>:44: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  publishers=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[5]\")\n",
      "<ipython-input-14-dd9f7bdb06f3>:54: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  genres=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[6]\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_name       Author_name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(2)\n",
    "\n",
    "# Opening the theguardian.com\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "#scrapping book names\n",
    "book_name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[2]\")\n",
    "    for i in names:\n",
    "        book_name.append(i.text)\n",
    "except NoSuchElementException:              #handling no such element exception\n",
    "    book_name.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "#scrapping author names\n",
    "author_name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[3]\")\n",
    "    for i in names:\n",
    "        author_name.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    author_name.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#scrapping Sale\n",
    "Sale=[]\n",
    "try:\n",
    "    sale=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[4]\")\n",
    "    for i in sale:\n",
    "        Sale.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    Sale.append('No details available')\n",
    "time.sleep(2)    \n",
    "\n",
    "#scrapping publisher\n",
    "publisher=[]\n",
    "try:\n",
    "    publishers=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[5]\")\n",
    "    for i in publishers:\n",
    "        publisher.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    publisher.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "#scrapping genre\n",
    "genre=[]\n",
    "try:\n",
    "    genres=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[6]\")\n",
    "    for i in genres:\n",
    "        genre.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    genre.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "#creating dataframe\n",
    "df=pd.DataFrame({\"Book_name\":book_name,\n",
    "                \"Author_name\":author_name,\n",
    "                'Volume sold':Sale,\n",
    "                'Publisher':publisher,\n",
    "                'Genre':genre})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348212b2",
   "metadata": {},
   "source": [
    "Q9. Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/ You have to find the following details: A) Name B) Year span C) Genre D) Run time E) Ratings F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cf90235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-f47f3efb0058>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n",
      "<ipython-input-15-f47f3efb0058>:13: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  names=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\")\n",
      "<ipython-input-15-f47f3efb0058>:24: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  span=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/span[2]\")\n",
      "<ipython-input-15-f47f3efb0058>:35: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  genres=driver.find_elements_by_xpath(\"//span[@class='genre']\")\n",
      "<ipython-input-15-f47f3efb0058>:46: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  info=driver.find_elements_by_xpath(\"//span[@class='runtime']\")\n",
      "<ipython-input-15-f47f3efb0058>:57: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  info=driver.find_elements_by_xpath(\"//div[@class='ipl-rating-star small']/span[2]\")\n",
      "<ipython-input-15-f47f3efb0058>:67: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  info=driver.find_elements_by_xpath(\"//span[@name='nv']\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>years</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1,962,385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>970,820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>934,863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>279,717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>239,868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>47,967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>58,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>186,514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>39,520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>222,926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name        years                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_time Rating      Votes  \n",
       "0    57 min    9.3  1,962,385  \n",
       "1    51 min    8.7    970,820  \n",
       "2    44 min    8.3    934,863  \n",
       "3    60 min    7.6    279,717  \n",
       "4    43 min    7.7    239,868  \n",
       "..      ...    ...        ...  \n",
       "95   42 min    7.6     47,967  \n",
       "96   50 min    7.8     58,679  \n",
       "97   42 min    8.2    186,514  \n",
       "98   45 min    7.1     39,520  \n",
       "99  572 min    8.6    222,926  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(2)\n",
    "\n",
    "# Opening the imdb.com\n",
    "url = \"https://www.imdb.com/list/ls095964455\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "# scraping name of webseries\n",
    "name=[]\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\")\n",
    "    for i in names:\n",
    "        name.append(i.text)\n",
    "except NosuchElementException:#handling no such element exception\n",
    "    name.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "# scraping year of release\n",
    "years=[]\n",
    "try:\n",
    "    span=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/span[2]\")\n",
    "    for i in span:\n",
    "        years.append(i.text)\n",
    "except NosuchElementException:#handling no such element exception\n",
    "    years.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "# scraping genre\n",
    "genre=[]\n",
    "try:\n",
    "    genres=driver.find_elements_by_xpath(\"//span[@class='genre']\")\n",
    "    for i in genres:\n",
    "        genre.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    genre.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "# scraping run_time\n",
    "run_time=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//span[@class='runtime']\")\n",
    "    for i in info:\n",
    "        run_time.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    run_time.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "# scraping rating\n",
    "rating=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//div[@class='ipl-rating-star small']/span[2]\")\n",
    "    for i in info:\n",
    "        rating.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    rating.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "# scraping votes\n",
    "votes=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//span[@name='nv']\")\n",
    "    for i in info:\n",
    "        votes.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    votes.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#creating dataframe\n",
    "df=pd.DataFrame({\"Name\":name,\n",
    "                \"years\":years,\n",
    "                \"Genre\":genre,\n",
    "                \"Run_time\":run_time,\n",
    "                \"Rating\":rating,\n",
    "                \"Votes\":votes})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33513e6f",
   "metadata": {},
   "source": [
    "Q10. Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/ You have to find the following details: A) Dataset name B) Data type C) Task D) Attribute type E) No of instances F) No of attribute G) Year Note: - from the home page you have to go to the ShowAllDataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26cc4a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-a0e267e0d536>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be51d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "url10 = 'https://archive.ics.uci.edu/'      \n",
    "driver.get(url10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0830573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-ed86bdcd9204>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  view = driver.find_element_by_xpath('//span[@class=\"whitetext\"][2]/a[1]')\n"
     ]
    }
   ],
   "source": [
    "view = driver.find_element_by_xpath('//span[@class=\"whitetext\"][2]/a[1]')\n",
    "view.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b233ba4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-3ebf61d12d88>:9: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  nam = driver.find_elements_by_xpath('//table[@cellpadding = \"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[1]')\n",
      "<ipython-input-51-3ebf61d12d88>:10: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  typ = driver.find_elements_by_xpath('//table[@cellpadding = \"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]')\n",
      "<ipython-input-51-3ebf61d12d88>:11: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  tas = driver.find_elements_by_xpath('//table[@cellpadding=\"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]')\n",
      "<ipython-input-51-3ebf61d12d88>:12: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  attri = driver.find_elements_by_xpath('//table[@cellpadding=\"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]')\n",
      "<ipython-input-51-3ebf61d12d88>:13: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  inst = driver.find_elements_by_xpath('//table[@cellpadding=\"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]')\n",
      "<ipython-input-51-3ebf61d12d88>:14: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  attri = driver.find_elements_by_xpath('//table[@cellpadding=\"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]')\n",
      "<ipython-input-51-3ebf61d12d88>:15: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  yea = driver.find_elements_by_xpath('//table[@cellpadding=\"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622\n",
      "622\n",
      "622\n",
      "622\n",
      "622\n",
      "622\n",
      "622\n"
     ]
    }
   ],
   "source": [
    "name = []  \n",
    "typee = []\n",
    "task = []\n",
    "attribute = []\n",
    "instances = []\n",
    "attributes = []\n",
    "year = []\n",
    "\n",
    "nam = driver.find_elements_by_xpath('//table[@cellpadding = \"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[1]')     \n",
    "typ = driver.find_elements_by_xpath('//table[@cellpadding = \"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]')\n",
    "tas = driver.find_elements_by_xpath('//table[@cellpadding=\"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]')\n",
    "attri = driver.find_elements_by_xpath('//table[@cellpadding=\"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]')\n",
    "inst = driver.find_elements_by_xpath('//table[@cellpadding=\"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]')\n",
    "attri = driver.find_elements_by_xpath('//table[@cellpadding=\"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]')\n",
    "yea = driver.find_elements_by_xpath('//table[@cellpadding=\"3\"]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]')\n",
    "\n",
    "for i in nam[1:]:                               \n",
    "    name.append(i.text)                        \n",
    "for j in typ[1:]:\n",
    "    typee.append(j.text)\n",
    "for k in tas[1:]:\n",
    "    task.append(k.text)\n",
    "for l in attri[1:]:\n",
    "    attribute.append(l.text)\n",
    "for m in inst[1:]:\n",
    "    instances.append(m.text)\n",
    "for n in attri[1:]:\n",
    "    attributes.append(n.text)\n",
    "for o in yea[1:]:\n",
    "    year.append(o.text)\n",
    "\n",
    "print(len(name))                          \n",
    "print(len(typee))\n",
    "print(len(task))\n",
    "print(len(attribute))\n",
    "print(len(instances))\n",
    "print(len(attributes))\n",
    "print(len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6e7e1ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Data Types</th>\n",
       "      <th>Default Task</th>\n",
       "      <th>Attribute Types</th>\n",
       "      <th>Number of Instances</th>\n",
       "      <th>Number of Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>8</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>14</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>38</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>294</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>279</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twit...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>525</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>50</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td>7</td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>16</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mo...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>2</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617    Influenza outbreak event prediction via Twit...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621    Image Recognition Task Execution Times in Mo...   \n",
       "\n",
       "                     Data Types          Default Task Attribute Types  \\\n",
       "0                 Multivariate        Classification               8    \n",
       "1                 Multivariate        Classification              14    \n",
       "2                 Multivariate        Classification              38    \n",
       "3                                Recommender-Systems             294    \n",
       "4                 Multivariate        Classification             279    \n",
       "..                          ...                   ...             ...   \n",
       "617               Multivariate        Classification             525    \n",
       "618               Multivariate        Classification              50    \n",
       "619                                   Classification               7    \n",
       "620  Multivariate, Time-Series        Classification              16    \n",
       "621                 Univariate            Regression               2    \n",
       "\n",
       "    Number of Instances Number of Attributes   Year  \n",
       "0                 4177                    8   1995   \n",
       "1                48842                   14   1996   \n",
       "2                  798                   38          \n",
       "3                37711                  294   1998   \n",
       "4                  452                  279   1998   \n",
       "..                  ...                  ...    ...  \n",
       "617              75840                  525   2020   \n",
       "618                400                   50   2020   \n",
       "619               1014                    7   2020   \n",
       "620              10129                   16   2021   \n",
       "621               4000                    2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10 = pd.DataFrame({'Name':name,\n",
    "                    'Data Types':typee,\n",
    "                    'Default Task':task,\n",
    "                    'Attribute Types':attribute,\n",
    "                    'Number of Instances':instances,\n",
    "                    'Number of Attributes':attributes,\n",
    "                    'Year':year})\n",
    "df10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876827bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
